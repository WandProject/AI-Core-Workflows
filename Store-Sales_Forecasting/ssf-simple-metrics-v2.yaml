apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: ssf-simple-metrics-v2  # Executable id, must be unique across all your workflows (YAML files)
  labels:
    scenarios.ai.sap.com/id: "ssf-simple-metrics"
    ai.sap.com/version: "2.0"
  annotations:
    scenarios.ai.sap.com/name: "Store Sales - Metrics"
    scenarios.ai.sap.com/description: "Evaluating the best regression to apply"
    
    executables.ai.sap.com/name: "Metrics [3 methods]"
    executables.ai.sap.com/description: "Generate metrics for 3 Regressions"
    
    artifacts.ai.sap.com/housedataset.kind: "dataset" # Helps in suggesting the kind of artifact that can be attached.
    artifacts.ai.sap.com/housemodel.kind: "model" # Helps in suggesting the kind of artifact that can be generated.

spec:
  imagePullSecrets:
    - name: wand-docker  # Docker registry secret
  entrypoint: mypipeline
  
  templates:
  - name: mypipeline
    steps:
    - - name: mypredictor
        template: mycodeblock1
  - name: mycodeblock1
    
    inputs:
      artifacts:  # placeholder for cloud storage attachements
        - name: store_dataset # a name for the placeholder
          path: /app/data/ # where to copy in the Dataset in the Docker image
    outputs:
      artifacts:
        - name: store_model # name of the artifact generated, and folder name when placed in S3, complete directory will be `../<executaion_id>/housepricemodel`
          globalName: store-sales-model # local identifier name to the workflow, also used above in annotation
          path: /app/model/ # from which folder in docker image (after running workflow step) copy contents to cloud storage
          archive:
            none:   # specify not to compress while uploading to cloud
              {}
    
    container:
      image: docker.io/wandproject/store-sales-forecasting:02  # Docker image name
      command: ["/bin/sh", "-c"]
      args:
        - "python /app/main.py"
